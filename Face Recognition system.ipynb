{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to read an image given the path to that image\n",
    "def read_image(image_file_path):\n",
    "    \n",
    "#     Using the inbuilt library function to read the image\n",
    "    image = face_recognition.load_image_file(image_file_path)\n",
    "    \n",
    "#     Recolouring the read image RGB standard\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "#     Returning the read image\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to create the encoding vector for the input image\n",
    "def encode_image(image):\n",
    "    \n",
    "#     Using the inbuilt library function to create the encoding vector\n",
    "    encoded_image = face_recognition.face_encodings(image)[0]\n",
    "    \n",
    "#     Returning the encoding vector\n",
    "    return encoded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to determine the location of the face in the input image\n",
    "def get_face_location(image):\n",
    "    \n",
    "#     Using the inbuilt library function to determine the boxed location of the face in the input image\n",
    "    face_location = face_recognition.face_locations(image)[0]\n",
    "    \n",
    "#     Returning the boxed location of the face in the input image\n",
    "    return face_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to encode all the existing images in the database\n",
    "def encode_stored_images(base_directory_path):\n",
    "    \n",
    "#     Creating an empty list of all encodings of all images in the database\n",
    "    encoded_stored_images = []\n",
    "    \n",
    "#     Traversing all images in the database\n",
    "    for image_file_name in os.listdir(base_directory_path):\n",
    "        \n",
    "#         Getting the exact file path for each image\n",
    "        image_file_path = base_directory_path + '/' + image_file_name\n",
    "        \n",
    "#         Reading each image file into an image object\n",
    "        image = read_image(image_file_path)\n",
    "    \n",
    "#         Creating the encoding vector of each image\n",
    "        encoded_image = encode_image(image)\n",
    "    \n",
    "#         Adding the current encoding vector to the list of all encodings\n",
    "        encoded_stored_images.append(encoded_image)\n",
    "    \n",
    "#     Returning the list of all encodings of all images in the database\n",
    "    return encoded_stored_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the name of person which most closely resembles the facial features of\n",
    "# the input subject \n",
    "def get_most_similar_person(subject_image, encoded_stored_images, people_list):\n",
    "    \n",
    "#     Creating the encoding vector of the input subject image\n",
    "    encoded_subject_image = encode_image(subject_image)\n",
    "    \n",
    "#     Creating the array of face_similarity_distances in which each element is the facial similarity\n",
    "#     distance between the input subject and the ith person in the database\n",
    "    face_similarity_distances = face_recognition.face_distance(encoded_stored_images,\n",
    "                                                               encoded_subject_image)\n",
    "    \n",
    "#     Getting the index of the person who most closely resembles the input subject\n",
    "    most_similar_face_index = np.argmin(face_similarity_distances)\n",
    "    \n",
    "#     Getting the name of the person who most closely resembles the input subject\n",
    "    most_similar_person = people_list[most_similar_face_index]\n",
    "    \n",
    "#     Returning the name of the person who most closely resembles the input subject\n",
    "    return most_similar_person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get the list of the names of all the people in the database\n",
    "def get_all_people_list(base_directory_path):\n",
    "    \n",
    "#     Creating an empty list of the names of all the people in the database \n",
    "    people_list = []\n",
    "    \n",
    "#     Traversing each image file in the database\n",
    "    for image_file_name in os.listdir(base_directory_path):\n",
    "        \n",
    "#         Getting the name of the person from the file\n",
    "        person_name = image_file_name.split('.')[0]\n",
    "    \n",
    "#         Adding the name of the person to the list of the names of all the people in the database\n",
    "        people_list.append(person_name)\n",
    "    \n",
    "#   Returning the list of the names of all the people in the database  \n",
    "    return people_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path to the folder to be treated as the databse of stored images\n",
    "# Accordingly change this path to where all the stored images are located in your machine\n",
    "stored_images_base_directory_path = 'C:\\Work\\Machine Learning projects\\Face Recognition system\\\n",
    "Family Database'\n",
    "\n",
    "# Getting the list of the names of all the people in the database\n",
    "people_list = get_all_people_list(stored_images_base_directory_path)\n",
    "\n",
    "# Creating the list of encoding vectors of all the images present in the database\n",
    "encoded_stored_images = encode_stored_images(stored_images_base_directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39083419 0.38646792 0.72575502 0.64611899] 1\n",
      "[0.40305509 0.39324979 0.74013552 0.64980647] 1\n",
      "[0.40511913 0.4018274  0.72133419 0.66124454] 1\n",
      "[0.41353959 0.3641193  0.75445334 0.65497616] 1\n",
      "Face not found\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-9eedbaebe1aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Face not found'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmost_similar_person_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_most_similar_person\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_face_frame\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_stored_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeople_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     cv2.rectangle(current_face_frame, (face_location[3], face_location[0]), (face_location[1], face_location[2]),\n\u001b[0;32m     13\u001b[0m                   (255,0,255),2)\n",
      "\u001b[1;32m<ipython-input-6-2b48486e824f>\u001b[0m in \u001b[0;36mget_most_similar_person\u001b[1;34m(subject_image, encoded_stored_images, people_list)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_most_similar_person\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_image\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_stored_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpeople_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mencoded_subject_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubject_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mface_similarity_distances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_distance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded_stored_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded_subject_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmost_similar_face_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_similarity_distances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mface_similarity_distances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmost_similar_face_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-ab27e3371994>\u001b[0m in \u001b[0;36mencode_image\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mencode_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mencoded_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mencoded_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Setting the parameters and source (webcam of the native machine) for the opencv functionality to\n",
    "# take input from the webcam of the native machine\n",
    "source = cv2.VideoCapture(0)\n",
    "\n",
    "# Running the application till the user wants\n",
    "while(True):\n",
    "    \n",
    "#     Reading the input image from the source \n",
    "    success, current_face_frame = source.read()\n",
    "    \n",
    "#     The read code above throws an exception if no face is found \n",
    "    try:\n",
    "        face_location = get_face_location(current_face_frame)\n",
    "    except:\n",
    "        print('Face not found')\n",
    "    \n",
    "#     Getting the name of the person that most closely resembles the input subject\n",
    "    most_similar_person_name = get_most_similar_person(current_face_frame, encoded_stored_images,\n",
    "                                                       people_list)\n",
    "    \n",
    "#     Boxing the face detected by Opencv for more interactive experience\n",
    "    cv2.rectangle(current_face_frame, (face_location[3], face_location[0]),\n",
    "                  (face_location[1], face_location[2]), (255,0,255),2)\n",
    "    \n",
    "#     Displaying the name of the person that most closely resembles the input subject\n",
    "    cv2.putText(current_face_frame, most_similar_person_name, (50, 50), cv2.FONT_HERSHEY_COMPLEX,\n",
    "                1,(0,0,255), 2)\n",
    "    \n",
    "#     Displaying the results in real time on the screen\n",
    "    cv2.imshow('LIVE', current_face_frame)\n",
    "    \n",
    "#     Get an input from the keyboard from the user\n",
    "    break_key = cv2.cv2.waitKey(1)\n",
    "    \n",
    "#     Defining the specific key that stops the application\n",
    "    if(break_key == 27):\n",
    "        break\n",
    "\n",
    "# Cleaning up after the application has stopped\n",
    "cv2.destroyAllWindows()\n",
    "source.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
